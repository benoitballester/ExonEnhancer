{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57fbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1: Get mouse coordiantes for hg ee and neg\n",
    "#awk '{print $1}' ee_dna_seqs.tsv |grep -Ff - lastznet_hg38_all_exons_treated.bed |sed 's/^chr//' > hg38_ee_mm39_coords.bed\n",
    "#awk '{print $1}' ctrlNeg_dna_seqs.tsv |grep -Ff - lastznet_hg38_all_exons_treated.bed |sed 's/^chr//' > hg38_neg_mm39_coords.bed\n",
    "\n",
    "### 2: Get fasta sequences of mouse for those coords\n",
    "#bedtools getfasta -name+ -fi Mus_musculus.GRCm39.dna.primary_assembly.fa -bed hg38_ee_mm39_coords.bed -fo hg38_ee_mm39_seq.fasta\n",
    "#bedtools getfasta -name+ -fi Mus_musculus.GRCm39.dna.primary_assembly.fa -bed hg38_neg_mm39_coords.bed -fo hg38_neg_mm39_seq.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b46ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "def reverse_complement(seq):\n",
    "    dna_seq = seq.upper()\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'N': 'N'}\n",
    "    return ''.join(complement[base] for base in reversed(dna_seq))\n",
    "\n",
    "ee_hg_seq_dna={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/ee_dna_seqs.tsv\") as file:\n",
    "    for line in file:            \n",
    "        if line.strip().split()[0][-1] == \"f\":\n",
    "            ee_hg_seq_dna[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        else:\n",
    "            ee_hg_seq_dna[line.strip().split()[0]] = reverse_complement(line.strip().split()[1])\n",
    "\n",
    "neg_hg_seq_dna={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/ctrlNeg_dna_seqs.tsv\") as file:\n",
    "    for line in file:            \n",
    "        if line.strip().split()[0][-1] == \"f\":\n",
    "            neg_hg_seq_dna[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        else:\n",
    "            neg_hg_seq_dna[line.strip().split()[0]] = reverse_complement(line.strip().split()[1])\n",
    "\n",
    "ee_hg_seq_aa={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/ee_aa_seqs_hg38.txt\") as file:\n",
    "    for line in file:            \n",
    "        ee_hg_seq_aa[line.strip().split()[0]] = line.strip().split()[1]\n",
    "\n",
    "neg_hg_seq_aa={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/neg_aa_seqs_hg38.txt\") as file:\n",
    "    for line in file:       \n",
    "        try:    \n",
    "            if line.strip().split()[1] != \"false\":\n",
    "                neg_hg_seq_aa[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "## Corresponding seqs in mouse \n",
    "ee_mm_seq_dna={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/hg38_ee_mm39_seq.fasta\") as file:\n",
    "    id = \"\"\n",
    "    for line in file:         \n",
    "        if line[0] == \">\":\n",
    "            id = (line.strip().split(\":\")[0]).split(\">\")[1]\n",
    "            continue\n",
    "        else:\n",
    "            if id[-1] == \"f\":\n",
    "                ee_mm_seq_dna[id] = line.strip().split()\n",
    "            else:\n",
    "                ee_mm_seq_dna[id] = reverse_complement(line.strip().split()[0])\n",
    "\n",
    "neg_mm_seq_dna={}\n",
    "with open(\"/home/mouren/Data/revisions/dn_ds/hg38_neg_mm39_seq.fasta\") as file:\n",
    "    id = \"\"\n",
    "    for line in file:         \n",
    "        if line[0] == \">\":\n",
    "            id = (line.strip().split(\":\")[0]).split(\">\")[1]\n",
    "            continue\n",
    "        else:\n",
    "            if id[-1] == \"f\":\n",
    "                neg_mm_seq_dna[id] = line.strip().split()\n",
    "            else:\n",
    "                neg_mm_seq_dna[id] = reverse_complement(line.strip().split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df22d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mouren/miniconda3/lib/python3.9/site-packages/Bio/Seq.py:2804: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Trim dna sequences so that that \n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def map_aa_to_dna(dna_seq, aa_seq):\n",
    "    dna_seq = dna_seq.upper()\n",
    "    aa_seq = aa_seq.upper()\n",
    "    \n",
    "    for offset in range(3):\n",
    "        # translate from the current offset\n",
    "        translated_seq = str(Seq(dna_seq[offset:]).translate(to_stop=False))\n",
    "        \n",
    "        # Case 1: Exact match starting from current offset\n",
    "        if translated_seq.startswith(aa_seq):\n",
    "            return offset, aa_seq, translated_seq\n",
    "        \n",
    "        # Case 2: Skip first AA because incomplete codon (missing bases)\n",
    "        if translated_seq.startswith(aa_seq[1:]):\n",
    "            return offset, aa_seq[1:], translated_seq\n",
    "        \n",
    "        # Case 3: translated_seq missing first AA, check starting from second AA\n",
    "        if translated_seq[1:].startswith(aa_seq[1:]):\n",
    "            return offset + 3, aa_seq[1:], translated_seq[1:]\n",
    "        \n",
    "    return None, None, None\n",
    "\n",
    "ee_hg_seq_dna_trimmed = {}\n",
    "ee_mm_seq_dna_trimmed = {}\n",
    "for exon_id, dna_seq in ee_hg_seq_dna.items():\n",
    "    #check if exon was lifted successfully \n",
    "    if exon_id in ee_mm_seq_dna:\n",
    "        mm_seq = ee_mm_seq_dna[exon_id]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    #check if we have aa seq for trimming\n",
    "    if exon_id in ee_hg_seq_aa:\n",
    "        aa_seq = ee_hg_seq_aa[exon_id]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    offset, matched_aa, translated_dna = map_aa_to_dna(dna_seq, aa_seq)\n",
    "    trimmed_dna_ee_hg = dna_seq[offset:]\n",
    "    trimmed_dna_ee_mm = mm_seq[offset:]\n",
    "\n",
    "    trimmed_dna_ee_hg_str = ''.join(base for base in trimmed_dna_ee_hg)\n",
    "    trimmed_dna_ee_mm_str = ''.join(base for base in trimmed_dna_ee_mm)\n",
    "    \n",
    "\n",
    "    if trimmed_dna_ee_hg_str != \"\" and trimmed_dna_ee_mm_str != \"\" and len(trimmed_dna_ee_hg_str) == len(trimmed_dna_ee_mm_str):\n",
    "        ee_hg_seq_dna_trimmed[exon_id] = trimmed_dna_ee_hg_str\n",
    "        ee_mm_seq_dna_trimmed[exon_id] = trimmed_dna_ee_mm_str\n",
    "\n",
    "neg_hg_seq_dna_trimmed = {}\n",
    "neg_mm_seq_dna_trimmed = {}\n",
    "for exon_id, dna_seq in neg_hg_seq_dna.items():\n",
    "    #check if exon was lifted successfully \n",
    "    if exon_id in neg_mm_seq_dna:\n",
    "        mm_seq = neg_mm_seq_dna[exon_id]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    #check if we have aa seq for trimming\n",
    "    if exon_id in neg_hg_seq_aa:\n",
    "        aa_seq = neg_hg_seq_aa[exon_id]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    offset, matched_aa, translated_dna = map_aa_to_dna(dna_seq, aa_seq)\n",
    "    trimmed_dna_neg_hg = dna_seq[offset:]\n",
    "    trimmed_dna_neg_mm = mm_seq[offset:]\n",
    "\n",
    "    trimmed_dna_neg_hg_str = ''.join(base for base in trimmed_dna_neg_hg)\n",
    "    trimmed_dna_neg_mm_str = ''.join(base for base in trimmed_dna_neg_mm)\n",
    "    \n",
    "\n",
    "    if trimmed_dna_neg_hg_str != \"\" and trimmed_dna_neg_mm_str != \"\" and len(trimmed_dna_neg_hg_str) == len(trimmed_dna_neg_mm_str):\n",
    "        neg_hg_seq_dna_trimmed[exon_id] = trimmed_dna_neg_hg_str\n",
    "        neg_mm_seq_dna_trimmed[exon_id] = trimmed_dna_neg_mm_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310fc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code to calculate dnds\n",
    "import copy\n",
    "from aa import codons\n",
    "import math\n",
    "import sys\n",
    "\n",
    "#split the sequence\n",
    "def split_seq(seq,n):\n",
    "    s=[]\n",
    "    for i in range(0,len(seq),n):\n",
    "        s.append(seq[i:i+n])\n",
    "    return s\n",
    "\n",
    "#Convert codon to amino acid\n",
    "def trans_2_condon(seq):\n",
    "    codons_list=[]\n",
    "    for base in split_seq(seq,3):\n",
    "        try:\n",
    "            codons_list.append(codons[base])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return codons_list\n",
    "\n",
    "#find the difference of 2 codon\n",
    "def diff(codon1,codon2):\n",
    "    df=[]\n",
    "    for base in range(0,3):\n",
    "        if codon1[base]!=codon2[base]:\n",
    "            df.append(base)\n",
    "    return df\n",
    "\n",
    "#find the possible pathway of amino acid conversion\n",
    "def trans(l):\n",
    "    if len(l)==1:\n",
    "        return [l]\n",
    "    if len(l)==2:\n",
    "        return [\n",
    "            l,\n",
    "            [l[1],l[0]]\n",
    "        ]\n",
    "    if len(l)==3:\n",
    "        return [l,\n",
    "[l[0],l[2],l[1]],\n",
    "[l[1],l[0],l[2]],\n",
    "[l[1],l[2],l[0]],\n",
    "[l[2],l[0],l[1]],\n",
    "[l[2],l[1],l[0]]\n",
    "]\n",
    "\n",
    "#find the pathway of of amino acid conversion\n",
    "def sd_nd(codon1,codon2):\n",
    "    snp_pos=diff(codon1,codon2)\n",
    "    pathway=trans(snp_pos)\n",
    "    combine=''\n",
    "    for aa in pathway:\n",
    "        new_condon=copy.deepcopy(codon1)\n",
    "        combine=combine+''.join(new_condon)\n",
    "        for base in aa:\n",
    "            new_condon[base]=codon2[base]\n",
    "            combine=combine+''.join(new_condon)\n",
    "    return (combine)\n",
    "\n",
    "\n",
    "#return the number of non-synonymous\n",
    "def count_diff(aa_list):\n",
    "    count=0\n",
    "    for i in range(0,len(aa_list)-1):\n",
    "        if aa_list[i]!=aa_list[i+1]:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#Input the out put of function sd_nd(), return sd and nd\n",
    "def sd_nd_cal(combine):\n",
    "    nd=0\n",
    "    pep=trans_2_condon(combine)\n",
    "    if len(pep)==2:\n",
    "        if pep[0]==pep[1]:\n",
    "            return [1,0]\n",
    "        else:\n",
    "            return [0,1]\n",
    "    elif len(pep)==6:\n",
    "        peplist=split_seq(pep,2)\n",
    "        for i in peplist:\n",
    "            nd+=count_diff(i)\n",
    "        return [(4-nd)/2,nd/2]\n",
    "    else:\n",
    "        peplist=split_seq(pep,4)\n",
    "        for i in peplist:\n",
    "            nd+=count_diff(i)\n",
    "            #print (i,count_diff(i))\n",
    "        return [(18-nd)/6,nd/6]\n",
    "\n",
    "def test_syno(codon1,codon2):\n",
    "    try:\n",
    "        if codons[codon1]==codons[codon2]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "#Compute the number of synonymous sites (s)\n",
    "def S_n(codon):\n",
    "    base={'A','G','C','T'}\n",
    "    s_num=0\n",
    "    for b in [0,1,2]:\n",
    "        try:\n",
    "            other_base=base-{codon[b]}\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for newbase in other_base:\n",
    "            try:\n",
    "                new_condon=codon[:b] + newbase + codon[b + 1:]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            s_num+=test_syno(codon,new_condon)\n",
    "    return (s_num)\n",
    "\n",
    "#Calculate the number of synonymous sites (s) and the number of nonsynonymous sites (n) for a sequence\n",
    "def s_n_seq(seq):\n",
    "    condon_list=split_seq(seq,3)\n",
    "    sd=0\n",
    "    for i in condon_list:\n",
    "        sd+=S_n(i)\n",
    "    nd=len(condon_list)*3-sd/3\n",
    "    return [sd/3,nd]\n",
    "\n",
    "#Compute the number of synonymous and nonsynonymous nucleotide differences between a pair of homologous sequences\n",
    "def ds_dn_seq(seq1,seq2):\n",
    "    condon_list1=split_seq(seq1,3)\n",
    "    condon_list2=split_seq(seq2,3)\n",
    "    sd_nd_val=[0,0]\n",
    "    for cond in range(0,len(condon_list1)):\n",
    "        c1=condon_list1[cond]\n",
    "        c2=condon_list2[cond]\n",
    "        if c1==c2:\n",
    "            pass\n",
    "        else:\n",
    "            xy=sd_nd(list(c1),list(c2))\n",
    "            sd_nd_exp2=sd_nd_cal(xy)\n",
    "            sd_nd_val[0]+=sd_nd_exp2[0]\n",
    "            sd_nd_val[1]+=sd_nd_exp2[1]\n",
    "    return sd_nd_val\n",
    "\n",
    "#Compute the dn/ds and pn/ps value\n",
    "def dnds(seq1,seq2):\n",
    "    assert len(seq1)==len(seq2),'Fatal err:length(seq1)!=length(seq2)'\n",
    "    if len(seq1)%3!=0: #'Fatal err:The length of input seq is not divisible by 3'\n",
    "        seq1 = seq1 + \"N\"\n",
    "        seq2 = seq2 + \"N\"\n",
    "        if len(seq1)%3!=0:\n",
    "            seq1 = seq1 + \"N\"\n",
    "            seq2 = seq2 + \"N\"\n",
    "    assert len(seq1)%3==0,'Fatal err:The length of input seq is not divisible by 3'\n",
    "    if seq1==seq2:\n",
    "        return None,None,None,None,None\n",
    "    sdnd1=s_n_seq(seq1)\n",
    "    sdnd2=s_n_seq(seq2)\n",
    "    sdnd=[(sdnd1[0]+sdnd2[0])/2,(sdnd1[1]+sdnd2[1])/2]\n",
    "    sd=ds_dn_seq(seq1,seq2)\n",
    "    ps=sd[0]/sdnd[0]\n",
    "    pn=sd[1]/sdnd[1]\n",
    "    \n",
    "    if ps >= 0.75 or pn >= 0.75:\n",
    "        #print(\"Too divergent for Jukes-Cantor correction. Skipping.\")\n",
    "        return pn, ps, float('nan'), float('nan'), float('nan')\n",
    "    \n",
    "    try:\n",
    "        ds=-0.75*math.log(1-(4*ps)/3)\n",
    "    except ValueError:\n",
    "        print(ps,pn,sdnd1,sdnd2,sd)\n",
    "    dn=-0.75*math.log(1-(4*pn)/3)\n",
    "\n",
    "    if ds == 0:\n",
    "        dnds = float('inf') if dn > 0 else float('nan')  # or set dnds = None\n",
    "    else:\n",
    "        dnds = dn / ds\n",
    "    return pn,ps,dn,ds,dnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d421c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute dN/dS\n",
    "import pandas as pd \n",
    "\n",
    "total_dnds_ee = []\n",
    "results_ee = [[\"ID\",\"pN\",\"pS\",\"dN\",\"dS\",\"dNdS\"]]\n",
    "sum_dn_ee = 0\n",
    "sum_ds_ee = 0\n",
    "for key,seq1 in ee_hg_seq_dna_trimmed.items():\n",
    "    seq2 = ee_mm_seq_dna_trimmed[key]\n",
    "    pn,ps,dn,ds,dn_ds = dnds(seq1,seq2)\n",
    "    if ds is not None and ds > 0 and dn is not None:\n",
    "        total_dnds_ee.append(dn / ds)\n",
    "        sum_dn_ee += dn\n",
    "        sum_ds_ee += ds\n",
    "    results_ee.append([key,pn,ps,dn,ds,dn_ds])\n",
    "\n",
    "total_dnds_neg = []\n",
    "results_neg = [[\"ID\",\"pN\",\"pS\",\"dN\",\"dS\",\"dNdS\"]]\n",
    "sum_dn_neg = 0\n",
    "sum_ds_neg = 0\n",
    "for key,seq1 in neg_hg_seq_dna_trimmed.items():\n",
    "    seq2 = neg_mm_seq_dna_trimmed[key]\n",
    "    pn,ps,dn,ds,dn_ds = dnds(seq1,seq2)\n",
    "    if ds is not None and ds > 0 and dn is not None:\n",
    "        total_dnds_neg.append(dn / ds)\n",
    "        sum_dn_neg += dn\n",
    "        sum_ds_neg += ds\n",
    "    results_neg.append([key,pn,ps,dn,ds,dn_ds])\n",
    "\n",
    "# Compute global dN/dS\n",
    "global_dnds_ee = sum_dn_ee / sum_ds_ee if sum_ds_ee > 0 else None\n",
    "global_dnds_neg = sum_dn_neg / sum_ds_neg if sum_ds_neg > 0 else None\n",
    "\n",
    "# Append total row\n",
    "results_ee.append([\"TOTAL\", \"NA\", \"NA\", sum_dn_ee, sum_ds_ee, global_dnds_ee])\n",
    "results_neg.append([\"TOTAL\", \"NA\", \"NA\", sum_dn_neg, sum_ds_neg, global_dnds_neg])\n",
    "\n",
    "df_ee = pd.DataFrame(results_ee).astype(str)\n",
    "df_ee.to_csv(\"//home/mouren/Data/revisions/dn_ds/hg_ee_dnds_mm.tsv\",sep=\"\\t\",header=False,index=False)\n",
    "\n",
    "df_neg = pd.DataFrame(results_neg).astype(str)\n",
    "df_neg.to_csv(\"//home/mouren/Data/revisions/dn_ds/hg_neg_dnds_mm.tsv\",sep=\"\\t\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd4ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median 0.08584161580822748\n",
      "median 0.08821830141414796\n",
      "mean 0.2687961604907738\n",
      "mean 0.2335094359605969\n",
      "\n",
      "Mann-Whitney U Test:\n",
      "U statistic = 10640535.5\n",
      "p-value = 0.0006280121415051488\n",
      "→ Significant difference in medians (p < 0.05)\n"
     ]
    }
   ],
   "source": [
    "### Perform statistical test on per-exon dN/dS\n",
    "from scipy.stats import chi2_contingency,mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Convert to float, remove invalids\n",
    "def clean_numeric(data):\n",
    "    cleaned = []\n",
    "    for v in data:\n",
    "        try:\n",
    "            f = float(v)\n",
    "            if not np.isnan(f):\n",
    "            #if np.isfinite(f):  # excludes NaN, inf, -inf\n",
    "                cleaned.append(f)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return cleaned\n",
    "\n",
    "clean_ee = clean_numeric(total_dnds_ee)\n",
    "clean_neg = clean_numeric(total_dnds_neg)\n",
    "\n",
    "print(\"median\",np.median(clean_ee))\n",
    "print(\"median\",np.median(clean_neg))\n",
    "\n",
    "print(\"mean\",np.mean(clean_ee))\n",
    "print(\"mean\",np.mean(clean_neg))\n",
    "\n",
    "stat, p_value = mannwhitneyu(clean_ee, clean_neg, alternative='two-sided')\n",
    "\n",
    "print(f\"\\nMann-Whitney U Test:\")\n",
    "print(f\"U statistic = {stat}\")\n",
    "print(f\"p-value = {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"→ Significant difference in medians (p < 0.05)\")\n",
    "else:\n",
    "    print(\"→ No significant difference in medians (p ≥ 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84a84f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 53.8741\n",
      "p-value: 2.138e-13\n",
      "Expected counts:\n",
      " [[1703.04926372 4557.72778686]\n",
      " [1339.06369192 3583.62375478]]\n"
     ]
    }
   ],
   "source": [
    "### TOTAL STATS\n",
    "# Build 2x2 table\n",
    "table = np.array([\n",
    "    [sum_dn_ee, sum_ds_ee],        # Disease: [pN, pS]\n",
    "    [sum_dn_neg, sum_ds_neg]  # Control: [pN, pS]\n",
    "])\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    "print(f\"Chi-squared: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4g}\")\n",
    "print(\"Expected counts:\\n\", expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede5f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGATGTGCGGAAGTTCAAGGAGACAAAGAAGCAGTTTGACAAGGTGCGGGAGGACCTGGAGCTGTCCCTGGTGAGGAACGCCCAGGCCCCGAGGCACCGGCCCCACGAGGTGGAGGAAGCCACCGGGGCCCTCACCCTCACCAGGAAGTGCTTCCGCCACCTGGCACTGGACTATGTGCTCCAG\n",
      "EDVRKFKETKKQFDKVREDLELSLVRNAQAPRHRPHEVEEATGALTLTRKCFRHLALDYVLQ\n",
      "GATGTGCGGAAGTTCAAGGAGACAAAGAAGCAGTTTGACAAGGTGCGGGAGGACCTGGAGCTGTCCCTGGTGAGGAACGCCCAGGCCCCGAGGCACCGGCCCCACGAGGTGGAGGAAGCCACCGGGGCCCTCACCCTCACCAGGAAGTGCTTCCGCCACCTGGCACTGGACTATGTGCTCCAG\n",
      "1 \n",
      " DVRKFKETKKQFDKVREDLELSLVRNAQAPRHRPHEVEEATGALTLTRKCFRHLALDYVLQ \n",
      " DVRKFKETKKQFDKVREDLELSLVRNAQAPRHRPHEVEEATGALTLTRKCFRHLALDYVLQ\n",
      "CCCGCCGCTGACTCAGTTCTTCTTGGAGTGTGGCGGCCTGGTGCGCACAGATAAGAAGCCAGCCCTGTGCAAGAGCTACCAGAAGCTGGTCTCTGAGGTCTGGCATAAGAAACG\n",
      "CPPLTQFFLECGGLVRTDKKPALCKSYQKLVSEVWHKK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mouren/miniconda3/lib/python3.9/site-packages/Bio/Seq.py:2804: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ENST00000315480.9_cds_8_0_chr9_129863186_f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(ee_hg_seq_dna[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENST00000315480.9_cds_8_0_chr9_129863186_f\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(ee_hg_seq_aa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENST00000315480.9_cds_8_0_chr9_129863186_f\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mee_hg_seq_dna_trimmed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mENST00000315480.9_cds_8_0_chr9_129863186_f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m offset, matched_aa, translated_dna \u001b[38;5;241m=\u001b[39m map_aa_to_dna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCCGCCGCTGACTCAGTTCTTCTTGGAGTGTGGCGGCCTGGTGCGCACAGATAAGAAGCCAGCCCTGTGCAAGAGCTACCAGAAGCTGGTCTCTGAGGTCTGGCATAAGAAACG\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPPLTQFFLECGGLVRTDKKPALCKSYQKLVSEVWHKK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(offset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, matched_aa, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, translated_dna)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ENST00000315480.9_cds_8_0_chr9_129863186_f'"
     ]
    }
   ],
   "source": [
    "### test trimming \n",
    "print(ee_hg_seq_dna[\"ENST00000353662.4_cds_3_0_chr1_1300509_r\"])\n",
    "print(ee_hg_seq_aa[\"ENST00000353662.4_cds_3_0_chr1_1300509_r\"])\n",
    "print(ee_hg_seq_dna_trimmed[\"ENST00000353662.4_cds_3_0_chr1_1300509_r\"])\n",
    "\n",
    "offset, matched_aa, translated_dna = map_aa_to_dna(\"GGATGTGCGGAAGTTCAAGGAGACAAAGAAGCAGTTTGACAAGGTGCGGGAGGACCTGGAGCTGTCCCTGGTGAGGAACGCCCAGGCCCCGAGGCACCGGCCCCACGAGGTGGAGGAAGCCACCGGGGCCCTCACCCTCACCAGGAAGTGCTTCCGCCACCTGGCACTGGACTATGTGCTCCAG\", \"EDVRKFKETKKQFDKVREDLELSLVRNAQAPRHRPHEVEEATGALTLTRKCFRHLALDYVLQ\")\n",
    "print(offset, \"\\n\", matched_aa, \"\\n\", translated_dna)\n",
    "\n",
    "print(ee_hg_seq_dna[\"ENST00000315480.9_cds_8_0_chr9_129863186_f\"])\n",
    "print(ee_hg_seq_aa[\"ENST00000315480.9_cds_8_0_chr9_129863186_f\"])\n",
    "print(ee_hg_seq_dna_trimmed[\"ENST00000315480.9_cds_8_0_chr9_129863186_f\"])\n",
    "\n",
    "offset, matched_aa, translated_dna = map_aa_to_dna(\"CCCGCCGCTGACTCAGTTCTTCTTGGAGTGTGGCGGCCTGGTGCGCACAGATAAGAAGCCAGCCCTGTGCAAGAGCTACCAGAAGCTGGTCTCTGAGGTCTGGCATAAGAAACG\", \"CPPLTQFFLECGGLVRTDKKPALCKSYQKLVSEVWHKK\")\n",
    "print(offset, \"\\n\", matched_aa, \"\\n\", translated_dna)\n",
    "\n",
    "print(ee_hg_seq_dna_trimmed[\"ENST00000353662.4_cds_3_0_chr1_1300509_r\"])\n",
    "print(ee_mm_seq_dna_trimmed[\"ENST00000353662.4_cds_3_0_chr1_1300509_r\"])\n",
    "\n",
    "#test dnds calculus\n",
    "print(ee_hg_seq_dna_trimmed[\"ENST00000379290.6_cds_13_0_chr1_1196600_f\"])\n",
    "print(ee_mm_seq_dna_trimmed[\"ENST00000379290.6_cds_13_0_chr1_1196600_f\"])\n",
    "\n",
    "\"\"\"print(ee_hg_seq_dna_trimmed[\"ENST00000315480.9_cds_8_0_chr9_129863186_f\"])\n",
    "print(ee_mm_seq_dna_trimmed[\"ENST00000315480.9_cds_8_0_chr9_129863186_f\"])\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
