{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### README:\n",
    "#### THE Dn/DS written in the files generated here are actually the Pn/Ps normalized, Dn/Ds is computed between species (human-mouse) in the other scritps.\n",
    "\n",
    "\n",
    "### Load Data\n",
    "def reverse_complement(seq):\n",
    "    dna_seq = seq.upper()\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "    return ''.join(complement[base] for base in reversed(dna_seq))\n",
    "\n",
    "## EE\n",
    "ee_pn={}\n",
    "ee_ps={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/hg38_ee_gnomAD_pNpS.tsv\") as file:\n",
    "    for line in file:   \n",
    "        try:         \n",
    "            ee_pn[line.strip().split()[0]] = int(line.strip().split()[2])\n",
    "            ee_ps[line.strip().split()[0]] = int(line.strip().split()[3])\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "ee_seq_dna={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/ee_dna_seqs.tsv\") as file:\n",
    "    for line in file:            \n",
    "        if line.strip().split()[0][-1] == \"f\":\n",
    "            ee_seq_dna[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        else:\n",
    "            ee_seq_dna[line.strip().split()[0]] = reverse_complement(line.strip().split()[1])\n",
    "\n",
    "ee_seq_aa={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/ee_aa_seqs_hg38.txt\") as file:\n",
    "    for line in file:            \n",
    "        ee_seq_aa[line.strip().split()[0]] = line.strip().split()[1]\n",
    "\n",
    "## NEG\n",
    "neg_pn={}\n",
    "neg_ps={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/hg38_neg_gnomAD_pNpS.tsv\") as file:\n",
    "    for line in file:            \n",
    "        try:\n",
    "            neg_pn[line.strip().split()[0]] = int(line.strip().split()[2])\n",
    "            neg_ps[line.strip().split()[0]] = int(line.strip().split()[3])\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "neg_seq_dna={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/ctrlNeg_dna_seqs.tsv\") as file:\n",
    "    for line in file:    \n",
    "        if line.strip().split()[0][-1] == \"f\":        \n",
    "            neg_seq_dna[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        else:\n",
    "            neg_seq_dna[line.strip().split()[0]] = reverse_complement(line.strip().split()[1])\n",
    "\n",
    "neg_seq_aa={}\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/neg_aa_seqs_hg38.txt\") as file:\n",
    "    for line in file:       \n",
    "        try:    \n",
    "            if line.strip().split()[1] != \"false\":\n",
    "                neg_seq_aa[line.strip().split()[0]] = line.strip().split()[1]\n",
    "        except IndexError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60fe09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def map_aa_to_dna(dna_seq, aa_seq):\n",
    "    dna_seq = dna_seq.upper()\n",
    "    aa_seq = aa_seq.upper()\n",
    "    \n",
    "    for offset in range(3):\n",
    "        # translate from the current offset\n",
    "        translated_seq = str(Seq(dna_seq[offset:]).translate(to_stop=False))\n",
    "        \n",
    "        # Case 1: Exact match starting from current offset\n",
    "        if translated_seq.startswith(aa_seq):\n",
    "            return offset, aa_seq, translated_seq\n",
    "        \n",
    "        # Case 2: Skip first AA because incomplete codon (missing bases)\n",
    "        if translated_seq.startswith(aa_seq[1:]):\n",
    "            return offset, aa_seq[1:], translated_seq\n",
    "        \n",
    "        # Case 3: translated_seq missing first AA, check starting from second AA\n",
    "        if translated_seq[1:].startswith(aa_seq[1:]):\n",
    "            return offset + 3, aa_seq[1:], translated_seq[1:]\n",
    "        \n",
    "    return None, None, None\n",
    "\n",
    "def count_sites(cds_seq):\n",
    "    \"\"\"Count possible synonymous and nonsynonymous sites in CDS.\"\"\"\n",
    "    S_sites, N_sites = 0.0, 0.0\n",
    "    cds_seq = cds_seq.upper()\n",
    "\n",
    "    for i in range(0, len(cds_seq) - 2, 3):\n",
    "        codon = cds_seq[i:i+3]\n",
    "        if \"N\" in codon or len(codon) != 3:\n",
    "            print(\"Test0\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ref_aa = Seq(codon).translate()\n",
    "        except:\n",
    "            print(\"Test\")\n",
    "            continue\n",
    "\n",
    "        syn, nonsyn = 0, 0\n",
    "        for pos in range(3):\n",
    "            for base in \"ACGT\":\n",
    "                if base == codon[pos]:\n",
    "                    continue\n",
    "                mutant = list(codon)\n",
    "                mutant[pos] = base\n",
    "                mutant_codon = \"\".join(mutant)\n",
    "                try:\n",
    "                    mutant_aa = Seq(mutant_codon).translate()\n",
    "                except:\n",
    "                    continue\n",
    "                if mutant_aa == ref_aa:\n",
    "                    syn += 1\n",
    "                else:\n",
    "                    nonsyn += 1\n",
    "\n",
    "        S_sites += syn / 9.0\n",
    "        N_sites += nonsyn / 9.0\n",
    "\n",
    "    return S_sites, N_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mouren/miniconda3/lib/python3.9/site-packages/Bio/Seq.py:2804: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Data import CodonTable\n",
    "import csv\n",
    "\n",
    "total_pN = total_pS = total_N_sites = total_S_sites = 0.0\n",
    "total_dnds_ee = []\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/normalized_pnps_ee.tsv\", \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"ExonID\", \"pN\", \"pS\", \"N_sites\", \"S_sites\", \"dN\", \"dS\", \"pN/pS\"])\n",
    "\n",
    "    for exon_id, dna_seq in ee_seq_dna.items():\n",
    "        if exon_id in ee_seq_aa:\n",
    "            aa_seq = ee_seq_aa[exon_id]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        offset, matched_aa, translated_dna = map_aa_to_dna(dna_seq, aa_seq)\n",
    "        trimmed_dna = dna_seq[offset:]\n",
    "        pN = ee_pn[exon_id]\n",
    "        pS = ee_ps[exon_id]\n",
    "        S_sites, N_sites = count_sites(trimmed_dna)\n",
    "\n",
    "        total_pN += pN\n",
    "        total_pS += pS\n",
    "        total_N_sites += N_sites\n",
    "        total_S_sites += S_sites\n",
    "\n",
    "        dN = pN / N_sites if N_sites > 0 else 0\n",
    "        dS = pS / S_sites if S_sites > 0 else 0\n",
    "        if dS == 0:\n",
    "            dn_ds = 0 if dN == 0 else \"Inf\"\n",
    "        else:\n",
    "            dn_ds = round(dN / dS, 6)\n",
    "\n",
    "        total_dnds_ee.append(dn_ds)\n",
    "        writer.writerow([exon_id, pN, pS, round(N_sites, 2), round(S_sites, 2),\n",
    "                            round(dN, 6), round(dS, 6), dn_ds])\n",
    "    \n",
    "    # === Compute overall dN/dS\n",
    "    dN_total = total_pN / total_N_sites if total_N_sites > 0 else 0\n",
    "    dS_total = total_pS / total_S_sites if total_S_sites > 0 else 0\n",
    "    if dS_total == 0:\n",
    "        dN_dS_total = 0 if dN_total == 0 else \"Inf\"\n",
    "    else:\n",
    "        dN_dS_total = round(dN_total / dS_total, 6)\n",
    "    writer.writerow([\"Total\", total_pN, total_pS, round(total_N_sites, 2), round(total_S_sites, 2),\n",
    "                            round(dN_total, 6), round(dS_total, 6), dN_dS_total])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e426e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEG\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Data import CodonTable\n",
    "import csv\n",
    "\n",
    "total_pN = total_pS = total_N_sites = total_S_sites = 0.0\n",
    "total_dnds_neg = []\n",
    "with open(\"/mnt/project/exonhancer/ZENODO_REPO_DISCARDED_JC_DONT_TOUCH/gnomADv3_analysis/0_get_snp_gnomad/exons/vcf_by_chr/normalized_pnps_neg.tsv\", \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"ExonID\", \"pN\", \"pS\", \"N_sites\", \"S_sites\", \"dN\", \"dS\", \"pN/pS\"])\n",
    "\n",
    "    for exon_id, dna_seq in neg_seq_dna.items():\n",
    "        if exon_id in neg_seq_aa:\n",
    "            aa_seq = neg_seq_aa[exon_id]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        offset, matched_aa, translated_dna = map_aa_to_dna(dna_seq, aa_seq)\n",
    "        trimmed_dna = dna_seq[offset:]\n",
    "        pN = neg_pn[exon_id]\n",
    "        pS = neg_ps[exon_id]\n",
    "        S_sites, N_sites = count_sites(trimmed_dna)\n",
    "\n",
    "        total_pN += pN\n",
    "        total_pS += pS\n",
    "        total_N_sites += N_sites\n",
    "        total_S_sites += S_sites\n",
    "\n",
    "        dN = pN / N_sites if N_sites > 0 else 0\n",
    "        dS = pS / S_sites if S_sites > 0 else 0\n",
    "        if dS == 0:\n",
    "            dn_ds = 0 if dN == 0 else \"Inf\"\n",
    "        else:\n",
    "            dn_ds = round(dN / dS, 6)\n",
    "\n",
    "        total_dnds_neg.append(dn_ds)\n",
    "        writer.writerow([exon_id, pN, pS, round(N_sites, 2), round(S_sites, 2),\n",
    "                            round(dN, 6), round(dS, 6), dn_ds])\n",
    "    \n",
    "    # === Compute overall dN/dS\n",
    "    dN_total = total_pN / total_N_sites if total_N_sites > 0 else 0\n",
    "    dS_total = total_pS / total_S_sites if total_S_sites > 0 else 0\n",
    "    if dS_total == 0:\n",
    "        dN_dS_total = 0 if dN_total == 0 else \"Inf\"\n",
    "    else:\n",
    "        dN_dS_total = round(dN_total / dS_total, 6)\n",
    "    writer.writerow([\"Total\", total_pN, total_pS, round(total_N_sites, 2), round(total_S_sites, 2),\n",
    "                            round(dN_total, 6), round(dS_total, 6), dN_dS_total])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "283e6617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median 0.586982\n",
      "median 0.551181\n",
      "mean 0.6326513612802613\n",
      "mean 0.6497246409420001\n",
      "\n",
      "Mann-Whitney U Test:\n",
      "U statistic = 90424349.0\n",
      "p-value = 1.0960299098202904e-21\n",
      "→ Significant difference in medians (p < 0.05)\n"
     ]
    }
   ],
   "source": [
    "### STATS\n",
    "from scipy.stats import chi2_contingency,mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Convert to float, remove invalids\n",
    "def clean_numeric(data):\n",
    "    cleaned = []\n",
    "    for v in data:\n",
    "        try:\n",
    "            f = float(v)\n",
    "            #if not np.isnan(f):\n",
    "            if np.isfinite(f):  # excludes NaN, inf, -inf\n",
    "                cleaned.append(f)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return cleaned\n",
    "\n",
    "clean_ee = clean_numeric(total_dnds_ee)\n",
    "clean_neg = clean_numeric(total_dnds_neg)\n",
    "\n",
    "print(\"median\", np.median(clean_ee))\n",
    "print(\"median\", np.median(clean_neg))\n",
    "\n",
    "print(\"mean\", np.mean(clean_ee))\n",
    "print(\"mean\", np.mean(clean_neg))\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "stat, p_value = mannwhitneyu(clean_ee, clean_neg, alternative='two-sided')\n",
    "\n",
    "print(f\"\\nMann-Whitney U Test:\")\n",
    "print(f\"U statistic = {stat}\")\n",
    "print(f\"p-value = {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"→ Significant difference in medians (p < 0.05)\")\n",
    "else:\n",
    "    print(\"→ No significant difference in medians (p ≥ 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8053d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared: 623.4202\n",
      "p-value: 1.349e-137\n",
      "Expected counts:\n",
      " [[552785.56302992 279507.43697008]\n",
      " [144706.43697008  73168.56302992]]\n"
     ]
    }
   ],
   "source": [
    "### total stats\n",
    "# Build 2x2 table\n",
    "table = np.array([\n",
    "    [547885.0, 284408.0],        # Disease: [pN, pS]\n",
    "    [149607.0, 68268.0]  # Control: [pN, pS]\n",
    "])\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    "print(f\"Chi-squared: {chi2:.4f}\")\n",
    "print(f\"p-value: {p:.4g}\")\n",
    "print(\"Expected counts:\\n\", expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
